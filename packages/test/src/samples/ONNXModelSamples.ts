import { getGlobalModelRepository } from "@workglow/ai";
import { HF_TRANSFORMERS_ONNX, HfTransformersOnnxModelRecord } from "@workglow/ai-provider";

export async function registerHuggingfaceLocalModels(): Promise<void> {
  const onnxModels: HfTransformersOnnxModelRecord[] = [
    {
      model_id: "onnx:Xenova/all-MiniLM-L6-v2:q8",
      title: "All MiniLM L6 V2 384D",
      description: "Xenova/all-MiniLM-L6-v2",
      tasks: ["TextEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "feature-extraction",
        modelPath: "Xenova/all-MiniLM-L6-v2",
        device: "webgpu",
        nativeDimensions: 384,
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/bge-base-en-v1.5:q8",
      title: "BGE Base English V1.5 768D",
      description: "Xenova/bge-base-en-v1.5",
      tasks: ["TextEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "feature-extraction",
        modelPath: "Xenova/bge-base-en-v1.5",
        device: "webgpu",
        nativeDimensions: 768,
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/gte-small:q8",
      title: "GTE Small 384D",
      description: "Xenova/gte-small",
      tasks: ["TextEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "feature-extraction",
        modelPath: "Xenova/gte-small",
        device: "webgpu",
        nativeDimensions: 384,
      },
      metadata: {},
    },
    {
      model_id: "onnx:onnx-community/bert_uncased_L-2_H-128_A-2-ONNX:q8",
      title: "BERT Uncased 128D",
      description: "onnx-community/bert_uncased_L-2_H-128_A-2-ONNX",
      tasks: ["TextEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "feature-extraction",
        modelPath: "onnx-community/bert_uncased_L-2_H-128_A-2-ONNX",
        device: "webgpu",
        nativeDimensions: 128,
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/paraphrase-albert-base-v2:q8",
      title: "Paraphrase ALBERT Base V2 768D",
      description: "Xenova/paraphrase-albert-base-v2",
      tasks: ["TextEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "feature-extraction",
        modelPath: "Xenova/paraphrase-albert-base-v2",
        device: "webgpu",
        nativeDimensions: 768,
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/distilbert-base-uncased-distilled-squad:q8",
      title: "distilbert-base-uncased-distilled-squad",
      description: "Xenova/distilbert-base-uncased-distilled-squad quantized to 8bit",
      tasks: ["TextQuestionAnsweringTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "question-answering",
        modelPath: "Xenova/distilbert-base-uncased-distilled-squad",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/gpt2:q8",
      title: "gpt2",
      description: "Xenova/gpt2 quantized to 8bit",
      tasks: ["TextGenerationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "text-generation",
        modelPath: "Xenova/gpt2",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/Phi-3-mini-4k-instruct:q4f16",
      title: "Phi-3-mini-4k-instruct:q4f16",
      description: "Xenova/Phi-3-mini-4k-instruct quantized to q4f16",
      tasks: ["TextGenerationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "text-generation",
        modelPath: "Xenova/Phi-3-mini-4k-instruct",
        device: "webgpu",
        dType: "q4f16",
        useExternalDataFormat: true,
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/distilgpt2:q8",
      title: "distilgpt2",
      description: "Xenova/distilgpt2 quantized to 8bit",
      tasks: ["TextGenerationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "text-generation",
        modelPath: "Xenova/distilgpt2",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/LaMini-Flan-T5-783M:q8",
      title: "LaMini-Flan-T5-783M",
      description: "Xenova/LaMini-Flan-T5-783M quantized to 8bit",
      tasks: ["TextGenerationTask", "TextRewriterTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "text2text-generation",
        modelPath: "Xenova/LaMini-Flan-T5-783M",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/LaMini-Flan-T5-783M:q8",
      title: "LaMini-Flan-T5-783M",
      description: "Xenova/LaMini-Flan-T5-783M quantized to 8bit",
      tasks: ["TextGenerationTask", "TextRewriterTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "text2text-generation",
        modelPath: "Xenova/LaMini-Flan-T5-783M",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Falconsai/text_summarization:q8",
      title: "text_summarization",
      description: "Falconsai/text_summarization quantized to 8bit",
      tasks: ["TextSummaryTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "summarization",
        modelPath: "Falconsai/text_summarization",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/nllb-200-distilled-600M:q8",
      title: "nllb-200-distilled-600M",
      description: "Xenova/nllb-200-distilled-600M quantized to 8bit",
      tasks: ["TextTranslationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "translation",
        modelPath: "Xenova/nllb-200-distilled-600M",
        languageStyle: "FLORES-200",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/m2m100_418M:q8",
      title: "m2m100_418M",
      description: "Xenova/m2m100_418M quantized to 8bit",
      tasks: ["TextTranslationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "translation",
        modelPath: "Xenova/m2m100_418M",
        languageStyle: "ISO-639",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/m2m100_418M:q8",
      title: "m2m100_418M",
      description: "Xenova/m2m100_418M quantized to 8bit",
      tasks: ["TextTranslationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "translation",
        modelPath: "Xenova/m2m100_418M",
        languageStyle: "ISO-639",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/mbart-large-50-many-to-many-mmt:q8",
      title: "mbart-large-50-many-to-many-mmt",
      description: "Xenova/mbart-large-50-many-to-many-mmt quantized to 8bit",
      tasks: ["TextTranslationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "translation",
        modelPath: "Xenova/mbart-large-50-many-to-many-mmt",
        languageStyle: "ISO-639_ISO-3166-1-alpha-2",
        dType: "q8",
      },
      metadata: {},
    },
    // Vision Models
    {
      model_id: "onnx:Xenova/vit-base-patch16-224:q8",
      title: "ViT Base Patch16 224",
      description: "Vision Transformer for image classification",
      tasks: ["ImageClassificationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "image-classification",
        modelPath: "Xenova/vit-base-patch16-224",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/clip-vit-base-patch32:q8",
      title: "CLIP ViT Base Patch32",
      description: "CLIP model for zero-shot image classification and embeddings",
      tasks: ["ImageClassificationTask", "ImageEmbeddingTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "zero-shot-image-classification",
        modelPath: "Xenova/clip-vit-base-patch32",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/detr-resnet-50:q8",
      title: "DETR ResNet-50",
      description: "Object detection model",
      tasks: ["ObjectDetectionTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "object-detection",
        modelPath: "Xenova/detr-resnet-50",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/owlvit-base-patch32:q8",
      title: "OWL-ViT Base Patch32",
      description: "Zero-shot object detection model",
      tasks: ["ObjectDetectionTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "zero-shot-object-detection",
        modelPath: "Xenova/owlvit-base-patch32",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/segformer-b0-finetuned-ade-512-512:q8",
      title: "Segformer B0 ADE",
      description: "Image segmentation model trained on ADE20K dataset",
      tasks: ["ImageSegmentationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "image-segmentation",
        modelPath: "Xenova/segformer-b0-finetuned-ade-512-512",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/vit-gpt2-image-captioning:q8",
      title: "ViT GPT2 Image Captioning",
      description: "Image to text captioning model",
      tasks: ["ImageToTextTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "image-to-text",
        modelPath: "Xenova/vit-gpt2-image-captioning",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/modnet:q8",
      title: "MODNet Background Removal",
      description: "Background removal model",
      tasks: ["BackgroundRemovalTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "background-removal",
        modelPath: "Xenova/modnet",
        dType: "q8",
      },
      metadata: {},
    },
    {
      model_id: "onnx:Xenova/mobilebert-uncased-mnli:q8",
      title: "MobileBERT MNLI",
      description: "Zero-shot text classification model",
      tasks: ["TextClassificationTask"],
      provider: HF_TRANSFORMERS_ONNX,
      providerConfig: {
        pipeline: "zero-shot-classification",
        modelPath: "Xenova/mobilebert-uncased-mnli",
        dType: "q8",
      },
      metadata: {},
    },
  ];

  for (const model of onnxModels) {
    await getGlobalModelRepository().addModel(model);
  }
}
